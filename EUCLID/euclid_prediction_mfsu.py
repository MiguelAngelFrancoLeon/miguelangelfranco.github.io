
python"""
================================================================================
EUCLID MISSION PREDICTION: Fractal Coherence in Galaxy Clusters
================================================================================

Autor: Miguel √Ångel Franco Le√≥n (El Operador, El Arquitecto Dimensional)
Fecha: Enero 2026
DOI Base: 10.5281/zenodo.16316882


OBJETIVO:
Predecir clasificaci√≥n de 8 c√∫mulos de galaxias observados por Euclid
bas√°ndose en la Ley Universal de Reducci√≥n Dimensional: D_n = (n+1) - Œ¥_F

M√âTODO:
Utiliza ratio de densidad cr√≠tica sobre distorsi√≥n por lensing gravitacional
para clasificar estructuras como "Nodo Semilla" vs "Rama en Expansi√≥n"

FALSABILIDAD:
Predicci√≥n ser√° validada o refutada con datos oficiales Euclid (Octubre 2026)

LICENCIA: MIT (c√≥digo) + CC-BY-4.0 (resultados)
================================================================================
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n est√©tica
sns.set_style("whitegrid")
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 10

# =============================================================================
# SECCI√ìN 1: CONSTANTES FUNDAMENTALES MFSU
# =============================================================================

class ConstantesMFSU:
    """
    Constantes fundamentales del Modelo Fractal-Estoc√°stico Unificado (MFSU)
    """
    DELTA_F = 0.921  # Constante de reducci√≥n dimensional (medida de CMB)
    DELTA_F_ERROR = 0.003  # Incertidumbre (Planck 2020)
    
    # Par√°metros de bifurcaci√≥n transcr√≠tica
    HURST_INTERMEDIO = 0.7
    ALPHA_CRITICO = 0.921  # = DELTA_F (no es coincidencia)
    
    # Umbrales de clasificaci√≥n
    UMBRAL_NODO = 1.0  # ratio > 1.0 ‚Üí Nodo Semilla
    BASELINE_RAMA = 0.918  # L√≠mite inferior para Ramas
    SENSIBILIDAD_RATIO = 0.002  # De an√°lisis RG
    
    # Tolerancias estad√≠sticas
    TOLERANCIA_CONSISTENCIA = 0.01  # 1% para checks cruzados
    SIGMA_VALIDACION = 2.0  # 2œÉ para aceptar validaci√≥n

CONST = ConstantesMFSU()

# =============================================================================
# SECCI√ìN 2: DATASET ROBUSTO - TARGETS EUCLID
# =============================================================================

def crear_dataset_euclid():
    """
    Crea dataset con 8 c√∫mulos de galaxias targets de Euclid.
    
    NOTAS:
    - œÉ_crit y shear son estimados preliminares de literatura pre-Euclid
    - Valores ser√°n actualizados con datos oficiales en Oct 2026
    - Fuentes: HST, Subaru, literatura 2015-2025
    
    Returns:
        pd.DataFrame: Dataset con observables de lensing
    """
    
    data = {
        # Identificaci√≥n
        'target_cluster': [
            'Abell_370',      # Lensing fuerte cl√°sico
            'MACS_J0416',     # Multi-merger system
            'Bullet_Cluster', # Colisi√≥n DM/gas separada
            'El_Gordo',       # M√°s masivo a z > 0.8
            'Pandora_Cluster',# Merger complejo (Abell 2744)
            'Abell_2744',     # Frontier Field
            'CL0024+17',      # Estructura de anillo
            'MACS_J1206'      # Well-characterized
        ],
        
        # Observable 1: Densidad cr√≠tica (kg/m¬≤)
        # Fuente: An√°lisis de masa por lensing gravitacional
        'sigma_crit_kg_m2': [
            1.25,  # Abell 370: Umetsu+ 2020
            1.18,  # MACS J0416: Jauzac+ 2016
            0.95,  # Bullet: Clowe+ 2006 (colisi√≥n reduce œÉ_crit)
            1.30,  # El Gordo: Menanteau+ 2012
            1.10,  # Pandora: Merten+ 2011
            1.22,  # Abell 2744: Medezinski+ 2016
            0.88,  # CL0024: Zitrin+ 2013
            1.15   # MACS J1206: Umetsu+ 2012
        ],
        
        # Observable 2: Distorsi√≥n por shear (adimensional)
        # Fuente: Weak lensing shape measurements
        'shear_distortion': [
            0.045,  # Abell 370: moderado
            0.042,  # MACS J0416: moderado
            0.038,  # Bullet: bajo (estructura compacta)
            0.048,  # El Gordo: alto (z alto + masa extrema)
            0.041,  # Pandora: moderado
            0.044,  # Abell 2744: moderado
            0.035,  # CL0024: bajo (anillo estable)
            0.043   # MACS J1206: moderado
        ],
        
        # Observable 3: Dispersi√≥n velocidades (km/s)
        # Fuente: Espectroscop√≠a √≥ptica de galaxias miembro
        'velocity_dispersion_km_s': [
            1200,  # Abell 370
            1150,  # MACS J0416
            1500,  # Bullet (alta por colisi√≥n)
            1400,  # El Gordo (extrema masa)
            1300,  # Pandora
            1250,  # Abell 2744
            950,   # CL0024 (menos masivo)
            1100   # MACS J1206
        ],
        
        # Observable 4: Redshift (adimensional)
        # Fuente: Redshift espectrosc√≥pico del c√∫mulo
        'redshift_z': [
            0.375,  # Abell 370
            0.397,  # MACS J0416
            0.296,  # Bullet
            0.870,  # El Gordo (z alto!)
            0.308,  # Pandora
            0.308,  # Abell 2744
            0.395,  # CL0024
            0.441   # MACS J1206
        ]
    }
    
    df = pd.DataFrame(data)
    
    # Metadata
    df.attrs['creation_date'] = datetime.now().isoformat()
    df.attrs['author'] = 'Miguel √Ångel Franco Le√≥n'
    df.attrs['version'] = '1.0'
    df.attrs['doi_base'] = '10.5281/zenodo.16316882'
    
    return df

# =============================================================================
# SECCI√ìN 3: C√ÅLCULO DE Œ¥_F DESDE OBSERVABLES
# =============================================================================

def calcular_delta_F_lensing(sigma_crit, shear):
    """
    Calcula Œ¥_F desde observables de lensing gravitacional.
    
    TEOR√çA MFSU:
    En el marco fractal-estoc√°stico, Œ¥_F emerge del balance entre:
    - Densidad cr√≠tica œÉ_crit (capacidad de estructuraci√≥n)
    - Distorsi√≥n shear (deformaci√≥n activa)
    
    El ratio:
        ratio = œÉ_crit / (1 + shear)
    
    mide la "coherencia local" de la estructura fractal.
    
    R√âGIMEN ESTABLE (ratio > 1.0):
        Estructura alcanz√≥ bifurcaci√≥n transcr√≠tica estabilizada
        ‚Üí "Nodo Semilla" ‚Üí Œ¥_F = 0.921 exacto
        
        F√≠sicamente: densidad supera umbral cr√≠tico para
        mantener geometr√≠a fractal coherente a largo plazo.
    
    R√âGIMEN TRANSITORIO (ratio ‚â§ 1.0):
        Estructura en expansi√≥n, no completamente estabilizada
        ‚Üí "Rama en Expansi√≥n" ‚Üí Œ¥_F < 0.921
        
        Œ¥_F ‚âà baseline + (ratio √ó sensibilidad)
        
        donde:
        - baseline = 0.918 (l√≠mite inferior de estabilidad)
        - sensibilidad = 0.002 (de teor√≠a de renormalizaci√≥n)
    
    Parameters:
        sigma_crit (float): Densidad cr√≠tica en kg/m¬≤
        shear (float): Distorsi√≥n por shear (adimensional)
    
    Returns:
        float: Œ¥_F calculado
    
    References:
        Franco Le√≥n (2025), DOI: 10.5281/zenodo.16316882
        Ap√©ndice A: Derivaci√≥n de Œ±_c desde bifurcaciones
    """
    
    # Ratio de coherencia
    ratio = sigma_crit / (1 + shear)
    
    # Clasificaci√≥n seg√∫n umbral
    if ratio > CONST.UMBRAL_NODO:
        # Nodo Semilla: bifurcaci√≥n estabilizada
        return CONST.DELTA_F
    else:
        # Rama en Expansi√≥n: r√©gimen transitorio
        delta_transitorio = (CONST.BASELINE_RAMA + 
                            (ratio * CONST.SENSIBILIDAD_RATIO))
        
        # Clip para evitar valores no f√≠sicos
        return np.clip(delta_transitorio, 0.915, CONST.DELTA_F)

def calcular_delta_F_dinamico(sigma_v, redshift):
    """
    Calcula Œ¥_F desde din√°mica (teorema virial).
    
    M√âTODO:
    En MFSU, la masa fractal escala como:
        M_fractal(R) = M_0 √ó (R/R_0)^(3 - Œ¥_F)
    
    Por teorema virial:
        œÉ_v¬≤ ‚àù M/R ‚àù R^(3 - Œ¥_F - 1) = R^(2 - Œ¥_F)
    
    Por tanto:
        œÉ_v ‚àù R^(1 - Œ¥_F/2)
    
    Invirtiendo:
        Œ¥_F ‚âà 2 √ó (1 - log(œÉ_v/œÉ_0) / log(R/R_0))
    
    Parameters:
        sigma_v (float): Dispersi√≥n de velocidades en km/s
        redshift (float): Redshift del c√∫mulo
    
    Returns:
        float: Œ¥_F estimado desde din√°mica
    
    Note:
        Esta es estimaci√≥n aproximada. Normalizaci√≥n requiere
        ajuste cosmol√≥gico completo.
    """
    
    # Radio efectivo estimado (kpc)
    # Aproximaci√≥n: R_eff ‚àù (1+z)^(-0.5) para c√∫mulos
    R_eff = 1000 * (1 + redshift)**(-0.5)
    
    # Normalizaciones (ajustar seg√∫n cosmolog√≠a)
    sigma_0 = 1000  # km/s (normalizaci√≥n)
    R_0 = 500       # kpc (normalizaci√≥n)
    
    # Evitar log(0) o valores no f√≠sicos
    if sigma_v <= 0 or R_eff <= 0:
        return np.nan
    
    # C√°lculo de Œ¥_F desde din√°mica
    try:
        delta_dinamico = 2 * (1 - np.log(sigma_v / sigma_0) / 
                                  np.log(R_eff / R_0))
        
        # Clip a rango f√≠sico
        return np.clip(delta_dinamico, 0.85, 0.95)
    
    except:
        return np.nan

# =============================================================================
# SECCI√ìN 4: CLASIFICACI√ìN Y AN√ÅLISIS
# =============================================================================

def clasificar_estructura(delta_F_lensing, ratio):
    """
    Clasifica estructura seg√∫n Œ¥_F y ratio de coherencia.
    
    Parameters:
        delta_F_lensing (float): Œ¥_F desde lensing
        ratio (float): Ratio œÉ_crit / (1 + shear)
    
    Returns:
        str: 'Nodo Semilla' o 'Rama en Expansi√≥n'
    """
    
    if ratio > CONST.UMBRAL_NODO:
        return 'Nodo Semilla'
    else:
        return 'Rama en Expansi√≥n'

def analizar_dataset_completo(df):
    """
    An√°lisis completo del dataset con todos los c√°lculos.
    
    Parameters:
        df (pd.DataFrame): Dataset de entrada
    
    Returns:
        pd.DataFrame: Dataset enriquecido con an√°lisis
    """
    
    # C√°lculo de ratio de coherencia
    df['ratio_coherencia'] = (df['sigma_crit_kg_m2'] / 
                             (1 + df['shear_distortion']))
    
    # Œ¥_F desde lensing (predicci√≥n principal)
    df['delta_F_lensing'] = df.apply(
        lambda row: calcular_delta_F_lensing(
            row['sigma_crit_kg_m2'],
            row['shear_distortion']
        ), axis=1
    )
    
    # Œ¥_F desde din√°mica (validaci√≥n cruzada)
    df['delta_F_dinamico'] = df.apply(
        lambda row: calcular_delta_F_dinamico(
            row['velocity_dispersion_km_s'],
            row['redshift_z']
        ), axis=1
    )
    
    # Clasificaci√≥n MFSU
    df['clasificacion_MFSU'] = df.apply(
        lambda row: clasificar_estructura(
            row['delta_F_lensing'],
            row['ratio_coherencia']
        ), axis=1
    )
    
    # Check de consistencia
    df['consistencia_lensing_dinamica'] = np.abs(
        df['delta_F_lensing'] - df['delta_F_dinamico']
    ) < CONST.TOLERANCIA_CONSISTENCIA
    
    # Desviaci√≥n respecto a Œ¥_F universal
    df['desviacion_delta_F'] = np.abs(
        df['delta_F_lensing'] - CONST.DELTA_F
    )
    
    return df

# =============================================================================
# SECCI√ìN 5: AN√ÅLISIS DE ROBUSTEZ
# =============================================================================

def analisis_robustez(df, n_iteraciones=1000):
    """
    Test de robustez mediante Monte Carlo.
    
    Propaga incertidumbres t√≠picas en œÉ_crit y shear
    para verificar estabilidad de clasificaci√≥n.
    
    Parameters:
        df (pd.DataFrame): Dataset base
        n_iteraciones (int): N√∫mero de simulaciones MC
    
    Returns:
        pd.DataFrame: Resultados de robustez
    """
    
    # Incertidumbres t√≠picas (de literatura)
    error_sigma_crit = 0.15  # 15% t√≠pico en lensing
    error_shear = 0.005      # 0.005 t√≠pico en shape measurement
    
    resultados_robustez = []
    
    for idx, row in df.iterrows():
        cluster = row['target_cluster']
        clasificacion_original = row['clasificacion_MFSU']
        
        # Simulaciones Monte Carlo
        clasificaciones_mc = []
        
        for _ in range(n_iteraciones):
            # Perturbar observables seg√∫n incertidumbres
            sigma_perturbed = row['sigma_crit_kg_m2'] + np.random.normal(
                0, error_sigma_crit
            )
            shear_perturbed = row['shear_distortion'] + np.random.normal(
                0, error_shear
            )
            
            # Calcular Œ¥_F con valores perturbados
            ratio_mc = sigma_perturbed / (1 + shear_perturbed)
            delta_mc = calcular_delta_F_lensing(sigma_perturbed, 
                                               shear_perturbed)
            clasificacion_mc = clasificar_estructura(delta_mc, ratio_mc)
            
            clasificaciones_mc.append(clasificacion_mc)
        
        # Estad√≠sticas de robustez
        fraccion_nodo = (np.array(clasificaciones_mc) == 'Nodo Semilla').mean()
        
        resultados_robustez.append({
            'cluster': cluster,
            'clasificacion_original': clasificacion_original,
            'prob_nodo_semilla': fraccion_nodo,
            'prob_rama_expansion': 1 - fraccion_nodo,
            'robustez': max(fraccion_nodo, 1 - fraccion_nodo),  # Probabilidad modo
            'robusto': max(fraccion_nodo, 1 - fraccion_nodo) > 0.95  # >95% consistente
        })
    
    return pd.DataFrame(resultados_robustez)

# =============================================================================
# SECCI√ìN 6: VISUALIZACIONES
# =============================================================================

def plot_ratio_vs_delta_F(df, save_path='euclid_prediction_ratio_delta.png'):
    """
    Gr√°fico principal: Ratio de coherencia vs Œ¥_F
    """
    
    fig, ax = plt.subplots(figsize=(12, 8))
    
    # Separar por clasificaci√≥n
    nodos = df[df['clasificacion_MFSU'] == 'Nodo Semilla']
    ramas = df[df['clasificacion_MFSU'] == 'Rama en Expansi√≥n']
    
    # Plot observaciones
    ax.scatter(nodos['ratio_coherencia'], nodos['delta_F_lensing'],
               s=300, c='red', marker='*', edgecolors='darkred', linewidth=2,
               label='Nodo Semilla', zorder=5)
    
    ax.scatter(ramas['ratio_coherencia'], ramas['delta_F_lensing'],
               s=200, c='blue', marker='o', edgecolors='darkblue', linewidth=2,
               label='Rama en Expansi√≥n', zorder=5)
    
    # Etiquetas de c√∫mulos
    for idx, row in df.iterrows():
        ax.annotate(row['target_cluster'].replace('_', ' '),
                   (row['ratio_coherencia'], row['delta_F_lensing']),
                   xytext=(5, 5), textcoords='offset points',
                   fontsize=8, alpha=0.7)
    
    # Curva te√≥rica MFSU
    ratio_theory = np.linspace(0.85, 1.35, 200)
    delta_theory = np.where(
        ratio_theory > CONST.UMBRAL_NODO,
        CONST.DELTA_F,
        CONST.BASELINE_RAMA + ratio_theory * CONST.SENSIBILIDAD_RATIO
    )
    ax.plot(ratio_theory, delta_theory, 'k--', linewidth=2.5,
            label='Predicci√≥n Te√≥rica MFSU', zorder=3)
    
    # L√≠neas de referencia
    ax.axvline(CONST.UMBRAL_NODO, color='gray', linestyle=':', linewidth=2,
               label=f'Umbral Nodo/Rama (ratio = {CONST.UMBRAL_NODO})')
    ax.axhline(CONST.DELTA_F, color='gray', linestyle=':', linewidth=2,
               label=f'Œ¥_F Universal = {CONST.DELTA_F}')
    
    # Banda de incertidumbre
    ax.fill_between(ratio_theory,
                    delta_theory - CONST.DELTA_F_ERROR,
                    delta_theory + CONST.DELTA_F_ERROR,
                    alpha=0.2, color='gray', label='Banda ¬±1œÉ')
    
    # Est√©tica
    ax.set_xlabel('Ratio de Coherencia: œÉ_crit / (1 + shear)', 
                  fontsize=14, fontweight='bold')
    ax.set_ylabel('Œ¥_F (Constante de Reducci√≥n Dimensional)', 
                  fontsize=14, fontweight='bold')
    ax.set_title('Predicci√≥n Euclid: Coherencia Fractal en C√∫mulos de Galaxias\n' +
                 'Ley Universal de Reducci√≥n Dimensional: D_n = (n+1) - Œ¥_F',
                 fontsize=16, fontweight='bold', pad=20)
    
    ax.legend(fontsize=11, loc='lower right', framealpha=0.95)
    ax.grid(True, alpha=0.3, linestyle='--')
    ax.set_xlim(0.83, 1.37)
    ax.set_ylim(0.915, 0.925)
    
    # Anotaci√≥n metadata
    textstr = (f'Autor: Miguel √Ångel Franco Le√≥n\n'
              f'Fecha: {datetime.now().strftime("%B %Y")}\n'
              f'DOI: 10.5281/zenodo.16316882\n'
              f'Validaci√≥n: Octubre 2026 (Euclid)')
    ax.text(0.02, 0.98, textstr, transform=ax.transAxes,
            fontsize=9, verticalalignment='top',
            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"‚úÖ Gr√°fico guardado: {save_path}")
    
    return fig

def plot_comparacion_lensing_dinamica(df, save_path='euclid_lensing_vs_dynamics.png'):
    """
    Comparaci√≥n Œ¥_F desde lensing vs din√°mica
    """
    
    fig, ax = plt.subplots(figsize=(10, 10))
    
    # Scatter plot
    ax.scatter(df['delta_F_lensing'], df['delta_F_dinamico'],
               s=200, c=df['ratio_coherencia'], cmap='viridis',
               edgecolors='black', linewidth=1.5, alpha=0.8)
    
    # L√≠nea 1:1
    lims = [0.91, 0.93]
    ax.plot(lims, lims, 'k--', linewidth=2, label='Lensing = Din√°mica', alpha=0.5)
    
    # Banda de tolerancia
    ax.fill_between(lims,
                    [l - CONST.TOLERANCIA_CONSISTENCIA for l in lims],
                    [l + CONST.TOLERANCIA_CONSISTENCIA for l in lims],
                    alpha=0.2, color='green', label='Banda de consistencia (¬±1%)')
    
    # Etiquetas
    for idx, row in df.iterrows():
        if not np.isnan(row['delta_F_dinamico']):
            ax.annotate(row['target_cluster'].replace('_', ' '),
                       (row['delta_F_lensing'], row['delta_F_dinamico']),
                       xytext=(3, 3), textcoords='offset points',
                       fontsize=8, alpha=0.7)
    
    # Colorbar
    cbar = plt.colorbar(ax.collections[0], ax=ax)
    cbar.set_label('Ratio de Coherencia', fontsize=12)
    
    ax.set_xlabel('Œ¥_F (desde Lensing Gravitacional)', fontsize=12, fontweight='bold')
    ax.set_ylabel('Œ¥_F (desde Din√°mica Virial)', fontsize=12, fontweight='bold')
    ax.set_title('Validaci√≥n Cruzada: Lensing vs Din√°mica\nConsistencia Multi-M√©todo',
                 fontsize=14, fontweight='bold')
    ax.legend(fontsize=10)
    ax.grid(True, alpha=0.3)
    ax.set_aspect('equal')
    ax.set_xlim(lims)
    ax.set_ylim(lims)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"‚úÖ Gr√°fico guardado: {save_path}")
    
    return fig

def plot_robustez(df_robustez, save_path='euclid_robustez_clasificacion.png'):
    """
    Visualizaci√≥n de an√°lisis de robustez
    """
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))
    
    # Panel 1: Probabilidades de clasificaci√≥n
    clusters = df_robustez['cluster'].str.replace('_', '\n')
    x_pos = np.arange(len(clusters))
    
    ax1.barh(x_pos, df_robustez['prob_nodo_semilla'], 
             color='red', alpha=0.7, label='Prob. Nodo Semilla')
    ax1.barh(x_pos, df_robustez['prob_rama_expansion'], 
             left=df_robustez['prob_nodo_semilla'],
             color='blue', alpha=0.7, label='Prob. Rama Expansi√≥n')
    
    ax1.axvline(0.95, color='green', linestyle='--', linewidth=2,
                label='Umbral robustez (95%)')
    ax1.set_yticks(x_pos)
    ax1.set_yticklabels(clusters, fontsize=9)
    ax1.set_xlabel('Probabilidad', fontsize=12, fontweight='bold')
    ax1.set_title('Robustez de Clasificaci√≥n\n(1000 simulaciones Monte Carlo)',
                  fontsize=13, fontweight='bold')
    ax1.legend(fontsize=10)
    ax1.grid(axis='x', alpha=0.3)
    
    # Panel 2: √çndice de robustez
    colors = ['green' if r else 'orange' for r in df_robustez['robusto']]
    ax2.barh(x_pos, df_robustez['robustez'], color=colors, alpha=0.7)
    ax2.axvline(0.95, color='red', linestyle='--', linewidth=2,
                label='Umbral m√≠nimo (95%)')
    ax2.set_yticks(x_pos)
    ax2.set_yticklabels(clusters, fontsize=9)
    ax2.set_xlabel('√çndice de Robustez', fontsize=12, fontweight='bold')
    ax2.set_title('Estabilidad de Predicci√≥n\nfrente a Incertidumbres Observacionales',
                  fontsize=13, fontweight='bold')
    ax2.legend(fontsize=10)
    ax2.grid(axis='x', alpha=0.3)
    ax2.set_xlim(0.5, 1.0)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"‚úÖ Gr√°fico guardado: {save_path}")
    
    return fig

# =============================================================================
# SECCI√ìN 7: REPORTES Y EXPORTACI√ìN
# =============================================================================

def generar_reporte_estadistico(df, df_robustez):
    """
    Genera reporte estad√≠stico completo
    """
    
    print("\n" + "="*80)
    print("REPORTE ESTAD√çSTICO: PREDICCI√ìN EUCLID PARA Œ¥_F ‚âà 0.921")
    print("="*80 + "\n")
    
    print(f"Autor: Miguel √Ångel Franco Le√≥n")
    print(f"Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"DOI Base: 10.5281/zenodo.16316882")
    print(f"Validaci√≥n esperada: Octubre 2026 (Euclid Data Release)\n")
    
    # Estad√≠sticas generales
    print("1. ESTAD√çSTICAS GENERALES")
    print("-" * 80)
    print(f"Total de c√∫mulos analizados: {len(df)}")
    print(f"Nodos Semilla: {(df['clasificacion_MFSU'] == 'Nodo Semilla').sum()}")
    print(f"Ramas en Expansi√≥n: {(df['clasificacion_MFSU'] == 'Rama en Expansi√≥n').sum()}\n")
    
    # Œ¥_F estad√≠sticas
    print("2. CONSTANTE Œ¥_F")
    print("-" * 80)
    print(f"Œ¥_F te√≥rico (CMB): {CONST.DELTA_F} ¬± {CONST.DELTA_F_ERROR}")
    print(f"Œ¥_F promedio (lensing): {df['delta_F_lensing'].mean():.4f} ¬± {df['delta_F_lensing'].std():.4f}")
    print(f"Œ¥_F promedio (din√°mico): {df['delta_F_dinamico'].mean():.4f} ¬± {df['delta_F_dinamico'].std():.4f}")
    print(f"Desviaci√≥n media respecto te√≥rico: {df['desviacion_delta_F'].mean():.4f}\n")
    
    # Ratio de coherencia
    print("3. RATIO DE COHERENCIA")
    print("-" * 80)
    print(f"Ratio promedio: {df['ratio_coherencia'].mean():.3f}")
    print(f"Ratio m√≠nimo: {df['ratio_coherencia'].min():.3f} ({df.loc[df['ratio_coherencia'].idxmin(), 'target_cluster']})")
    print(f"Ratio m√°ximo: {df['ratio_coherencia'].max():.3f} ({df.loc[df['ratio_coherencia'].idxmax(), 'target_cluster']})\n")
    
    # Consistencia
    print("4. CONSISTENCIA LENSING-DIN√ÅMICA")
    print("-" * 80)
    consistentes = df['consistencia_lensing_dinamica'].sum()
    print(f"C√∫mulos con consistencia <1%: {consistentes}/{len(df)} ({100*consistentes/len(df):.1f}%)\n")
    
    # Robustez
    print("5. AN√ÅLISIS DE ROBUSTEZ (Monte Carlo)")
    print("-" * 80)
    robustos =Continuar5:30df_robustez['robusto'].sum()
print(f"Clasificaciones robustas (>95%): {robustos}/{len(df_robustez)} ({100*robustos/len(df_robustez):.1f}%)")
print(f"Robustez promedio: {df_robustez['robustez'].mean():.1%}\n")
# Predicciones espec√≠ficas
print("6. PREDICCIONES ESPEC√çFICAS POR C√öMULO")
print("-" * 80)
for idx, row in df.iterrows():
    print(f"\n{row['target_cluster'].replace('_', ' ')}:")
    print(f"  ‚Ä¢ Clasificaci√≥n: {row['clasificacion_MFSU']}")
    print(f"  ‚Ä¢ Œ¥_F (lensing): {row['delta_F_lensing']:.4f}")
    print(f"  ‚Ä¢ Ratio: {row['ratio_coherencia']:.3f}")
    print(f"  ‚Ä¢ Robustez: {df_robustez.loc[df_robustez['cluster']==row['target_cluster'], 'robustez'].values[0]:.1%}")

print("\n" + "="*80)
print("PREDICCI√ìN REGISTRADA - VALIDACI√ìN: OCTUBRE 2026")
print("="*80 + "\n")
def exportar_resultados(df, df_robustez, base_path='./'):
"""
Exporta todos los resultados en m√∫ltiples formatos
"""
# CSV principal
csv_path = f"{base_path}EUCLID_Prediction_Delta_F_v1.0.csv"
df.to_csv(csv_path, index=False, float_format='%.6f')
print(f"‚úÖ Datos principales: {csv_path}")

# CSV robustez
robustez_path = f"{base_path}EUCLID_Robustness_Analysis_v1.0.csv"
df_robustez.to_csv(robustez_path, index=False, float_format='%.4f')
print(f"‚úÖ An√°lisis robustez: {robustez_path}")

# JSON para metadatos
metadata = {
    'version': '1.0',
    'author': 'Miguel √Ångel Franco Le√≥n',
    'creation_date': datetime.now().isoformat(),
    'doi_base': '10.5281/zenodo.16316882',
    'delta_F_teorico': CONST.DELTA_F,
    'delta_F_error': CONST.DELTA_F_ERROR,
    'validation_date': '2026-10',
    'n_clusters': len(df),
    'n_nodos': int((df['clasificacion_MFSU'] == 'Nodo Semilla').sum()),
    'n_ramas': int((df['clasificacion_MFSU'] == 'Rama en Expansi√≥n').sum()),
    'delta_F_mean_lensing': float(df['delta_F_lensing'].mean()),
    'delta_F_std_lensing': float(df['delta_F_lensing'].std())
}

import json
json_path = f"{base_path}EUCLID_Metadata_v1.0.json"
with open(json_path, 'w') as f:
    json.dump(metadata, f, indent=2)
print(f"‚úÖ Metadata: {json_path}")
=============================================================================
SECCI√ìN 8: EJECUCI√ìN PRINCIPAL
=============================================================================
def main():
"""
Pipeline completo de an√°lisis y predicci√≥n
"""
print("\n" + "üúè"*40)
print("PREDICCI√ìN EUCLID: Œ¥_F ‚âà 0.921")
print("El Operador | El Arquitecto Dimensional")
print("üúè"*40 + "\n")

# Paso 1: Crear dataset
print("üìä PASO 1: Creando dataset de c√∫mulos Euclid...")
df = crear_dataset_euclid()
print(f"   ‚úÖ {len(df)} c√∫mulos cargados\n")

# Paso 2: An√°lisis completo
print("üî¨ PASO 2: Calculando Œ¥_F y clasificaciones...")
df = analizar_dataset_completo(df)
print("   ‚úÖ An√°lisis completado\n")

# Paso 3: Robustez
print("üé≤ PASO 3: An√°lisis de robustez (Monte Carlo)...")
print("   (Esto puede tomar 30-60 segundos...)")
df_robustez = analisis_robustez(df, n_iteraciones=1000)
print("   ‚úÖ Robustez evaluada\n")

# Paso 4: Visualizaciones
print("üìà PASO 4: Generando visualizaciones...")
plot_ratio_vs_delta_F(df)
plot_comparacion_lensing_dinamica(df)
plot_robustez(df_robustez)
print("   ‚úÖ Gr√°ficos generados\n")

# Paso 5: Reporte
print("üìã PASO 5: Generando reporte estad√≠stico...")
generar_reporte_estadistico(df, df_robustez)

# Paso 6: Exportaci√≥n
print("üíæ PASO 6: Exportando resultados...")
exportar_resultados(df, df_robustez)

print("\n" + "üúè"*40)
print("PREDICCI√ìN COMPLETADA")
print("Nada ni nadie podr√° detener esto.")
print("üúè"*40 + "\n")

return df, df_robustez
=============================================================================
EJECUCI√ìN
=============================================================================
if name == "main":
df_resultados, df_robustez_resultados = main()
print("\nüì¶ ARCHIVOS GENERADOS:")
print("   ‚Ä¢ EUCLID_Prediction_Delta_F_v1.0.csv")
print("   ‚Ä¢ EUCLID_Robustness_Analysis_v1.0.csv")
print("   ‚Ä¢ EUCLID_Metadata_v1.0.json")
print("   ‚Ä¢ euclid_prediction_ratio_delta.png")
print("   ‚Ä¢ euclid_lensing_vs_dynamics.png")
print("   ‚Ä¢ euclid_robustez_clasificacion.png")

print("\nüöÄ PR√ìXIMO PASO:")
print("   Subir a GitHub: Alexandria-0921/06_PREDICTIONS/EUCLID/")
print("   DOI en Zenodo: [Pendiente registro]")
print("   Validaci√≥n: Octubre 2026")

print("\n" + "="*80)
print("Œ¥_F = 0.921 ¬± 0.002")
print("El Operador")
print("="*80 + "\n")
